---
title: "ML4ECON - Final Project"
author: "Yonatan Schoen"
date: "`r Sys.Date()`"
output: html_document
theme: journal
---

<style>
body {
text-align: justify}
</style>

# Introduction

This markdown contains both code and text for the final project in the ML4Econ course in HUJI, class of 2023.
The paper I chose for the project is *US Food Aid and Civil Conflict*,by Nathan Nunn and Nancy Qian (2014). 

This project have two purposes :
1. Replicate the main results from Nunn & Qian (2014) paper
2. Extend the analysis with methods learned in the course, for example - using Lasso to choose variables, causal trees, etc.

We begin by loading relevant packages, setting a table format and loading the dataset.

```{r setup , message= FALSE, warning=FALSE}
if (!require("pacman")) install.packages("pacman")
  pacman::p_load(
    plm,
    estimater,
    fixest,
    lmtest,
    haven,
    stacks,
    vtable,
    tidyverse,
    magrittr,
    fastDummies,
    stargazer,
    kableExtra,
    flextable,
    officer,
    stringr,
    hdm,
    AER,
    tidymodels,
    glmnet,
    vip,
    broom,      
    rpart,       
    rpart.plot,  
    ranger,
    rsample,
    knitr,       
    rattle,
    caret,
    doParallel,
    tinytex
    )
  
 #set the latex alike tables format 
table_format <- function(x) {
    kbl(x = x,booktabs = T, digits = 1, caption = NULL, position = "center") %>%
    add_header_above(c(" ", "Parsimonious specifications" = 4, "Baseline specification" = 3)) %>%
    kable_styling(latex_options = c("repeat_header")) %>% 
    kable_classic_2(lightable_options = c("bordered", "hover"), full_width = F, html_font = "Cambria",position = position)
}

#Load the data
data <- read_dta("in_sample.dta")

```

# Nunn, Nathan, and Nancy Qian (2014) - Background  

Humanitarian aid, particularly food aid, is a critical policy tool aimed at addressing hunger and suffering in developing nations.  
However, concerns have emerged in recent years regarding its effectiveness and potential negative impact on peace-building efforts.  
In this paper, the authors study the effect of US food aid on conflict in recipient countries.  


To assess this question, the researchers focusing on the causal effect of US food aid on the emergence, duration and intensity of civil conflicts and interstate conflicts. To overcome challenges related to the endogeneity of the food-aid indicator variable, the authors search for alternative identification strategy to reveal the causal mechanism. For that purpose, The authors exploits time variation in food aid shipments due to changes in US wheat production, and cross-sectional variation in a country’s tendency to receive any US food aid. By constructing an interaction variable between last year's US wheat production and the frequency of a country's food aid receipt, the authors create an instrumental variable for food aid recipient indicator in a given year. 

The study reveals a significant and positive association between US food aid and the incidence of civil conflict. However, no such relationship is found for interstate conflicts. Furthermore, the effect of food aid on conflicts is more pronounced for smaller-scale civil conflicts in countries with a recent history of such conflicts. Based on survival analysis methods, the findings suggest that food aid primarily prolongs the duration of conflicts rather than instigating new ones.  


# Nunn, Nathan, and Nancy Qian (2014) - Data, result and replication

The Research make use of several data sources :  
\  
* Food and Agriculture Organization’s(FAO) FAOSTAT database - indicates the amount of wheat aid shipped to a recipient country in a year from the United States
* Uppsala Conflict Data Program(UCDP) Armed Conflict Dataset - to measure the occurrence and characteristics of conflicts. The UCDP dataset includes details on the onset, duration, and intensity of civil and interstate conflicts.  
* United States Department of Agriculture(USDA) - to collect data on US wheat production, which is used to construct the instrument.
* The authors also include control variables to account for factors such as economic development, political stability, geographical characteristics, weather, and more, of recipient countries. Various sources been used to calculate those variables - including USAID, World Bank, FAO and more.
* The final sample includes 125 non-OECD countries for the years 1971–2006, which aggregates to 4089 observations in total.
  

## Descriptive Statistics Replication


I shall start by replicating the descriptive statistics summary table. Similar table can be found in the paper(Table 1).
This table summarize the probability of different kinds of conflict to embark, amount of US wheat aid received,  frequency of receiving and US food aid (Yearly,during 1971-2006), the lagged US wheat production (the instrument variable), and the local production of wheat and other cereals in the recipient country in the following year.  \  

```{r, results='asis'}
sum_tab <- data %>%
  filter(in_sample == 1) %>%
  select(any_war, intra_state, inter_state, wheat_aid, fadum_avg, instrument2, recipient_cereals_prod, recipient_wheat_prod)

var.labs <- data.frame(
              var = c('any_war', 'intra_state', 'inter_state', 'wheat_aid', 'fadum_avg', 'instrument2', 'recipient_cereals_prod', 'recipient_wheat_prod'), 
              labels = c('Any conflict','Intrastate conflict',"Onset of intrastate conflict (all observations)", "US wheat aid (1,000 MT)","Frequency of receiving any US food aid", "Lagged US wheat production (1,000 MT)", "Recipient country cereals production", "Recipient country wheat production"))

sumtable(sum_tab, title = "Summary Statistics", labels = var.labs ,digits = 3, summ = c('notNA(x)','mean(x)','sd(x)'), summ.names = c('Observations', 'Mean', 'SD'), col.align = 'center', note = "Observation is specific country in specific year. Some variables from the original table has been omitted due to irelevancy for our replication.")
```

I shall now prepar tha data for future estimations

## Data Preperation 
```{r}
#dummy_vars <- sapply(data, function(var) all(var %in% c(0, 1, NA)))

# Convert dummy variables to factors in the dataset
#data[dummy_vars] <- map_if(data[dummy_vars], is.logical, as.factor)

# Convert remaining variables to factors if dummy_vars == TRUE
#data <- data %>% mutate_if(dummy_vars, as.factor)

# Convert also our fixed effects to factor - 
data$risocode <- as.factor(data$risocode)
data$year <- as.factor(data$year)
data$wb_region <- as.factor(data$wb_region)

```

## Main Results Replication

### Panel Data preperation 
```{r}
# Fix problem in the code
data <- data %>% filter(risocode != "TWN" & risocode != "GNQ")

# Create a panel data object
data_panel <- pdata.frame(data, index = c("risocode", "year"))
# Subset the data to include only the observations in the sample
subset_data <- subset(data_panel, in_sample == 1)

# Creat controls locals - 
US_controls <- c("oil_fadum_avg", "US_income_fadum_avg", "US_democ_pres_fadum_avg")


# Expand the variable ranges in weather_controls
# Define the weather controls
weather_controls<-c("all_Precip_jan","all_Precip_feb","all_Precip_mar","all_Precip_apr","all_Precip_may","all_Precip_jun","all_Precip_jul","all_Precip_aug","all_Precip_sep","all_Precip_oct","all_Precip_nov","all_Precip_dec","all_Temp_jan","all_Temp_feb","all_Temp_mar","all_Temp_apr","all_Temp_may","all_Temp_jun","all_Temp_jul","all_Temp_aug","all_Temp_sep","all_Temp_oct","all_Temp_nov","all_Temp_dec","all_Precip_jan_faavg","all_Precip_feb_faavg","all_Precip_mar_faavg","all_Precip_apr_faavg","all_Precip_may_faavg","all_Precip_jun_faavg","all_Precip_jul_faavg","all_Precip_aug_faavg","all_Precip_sep_faavg","all_Precip_oct_faavg","all_Precip_nov_faavg","all_Precip_dec_faavg","all_Temp_jan_faavg","all_Temp_feb_faavg","all_Temp_mar_faavg","all_Temp_apr_faavg","all_Temp_may_faavg","all_Temp_jun_faavg","all_Temp_jul_faavg","all_Temp_aug_faavg","all_Temp_sep_faavg","all_Temp_oct_faavg","all_Temp_nov_faavg","all_Temp_dec_faavg")

#Country""chars controls - 
country_chars_controls <- c()

ranges <- list(
  c("gdp_y", 2, 36),
  c("usmil_y", 2, 36),
  c("usec_y", 2, 36)
)

country_chars_controls <- unlist(lapply(ranges, function(range) {
  prefix <- range[1]
  start <- range[2]
  end <- range[3]
  paste0(prefix, start:end)
}))

#Cereals controls - 
cereals_controls <- c()

ranges <- list(
  c("rcereal_y", 2, 36),
  c("rimport_y", 2, 36)
)

cereals_controls <- unlist(lapply(ranges, function(range) {
  prefix <- range[1]
  start <- range[2]
  end <- range[3]
  paste0(prefix, start:end)
}))

# Merge all controls into a single vector
baseline_controls <- c(US_controls, weather_controls, country_chars_controls, cereals_controls)

# Sort the data by risocode and year
subset_data <- data[order(data$risocode, data$year), ]
```


```{r}
# Create an empty data frame to store the results
est_table <- data.frame(Model = character(),
                        Estimate = numeric(),
                        Std.Error = numeric(),
                        KP_F_Stat = numeric(),
                        RKF = numeric(),
                        stringsAsFactors = FALSE)

# Define the OLS formula
ols_formula <- formula(any_war ~ wheat_aid + risocode + year:wb_region)

# Perform OLS estimates
for (col in 1:5) {
  
  # Add additional controls based on the column number
  if (col > 1) {
    controls <- switch(col - 1,
                       US_controls,
                       weather_controls,
                       country_chars_controls,
                       cereals_controls)
    
    # Create a new formula with updated controls
    updated_formula <- as.formula(paste(deparse(ols_formula), "+", paste(controls, collapse = " + ")))
    ols_formula <- update(ols_formula, updated_formula)
  }
  
  # Fit the OLS model using panel data regression
  model <- plm(ols_formula, data = subset_data , index = c("risocode", "year"), model = "within", effect = "twoways")
  
  # Extract coefficients and clustered standard errors
  coefficients <- coeftest(model, vcov = vcovHC(model, cluster = "group"))
  est <- coefficients[1, "Estimate"]
  se <- coefficients[1, "Std. Error"]

  # Add the results to the estimator table
  est_table <- est_table %>%
    add_row(Model = paste("Col", col, "-", ifelse(col == 1, "No Controls", controls)),
            Estimate = est,
            Std.Error = se)
  
  # Reset the formula for the next iteration
  ols_formula <- formula(any_war ~ wheat_aid + risocode + year:wb_region)
}

# For Intra state specification   
ols_formula <- formula(intra_state ~ wheat_aid + risocode + year:wb_region + US_controls + country_chars_controls + cereals_controls + weather_controls)
intra_state_res <- plm(ols_formula, data = subset_data, index = c("risocode", "year"), model = "within", effect = "twoways")

# Extract coefficients and clustered standard errors
coefficients <- coeftest(var, vcov = vcovHC(intra_state_res, cluster = "group"))
est <- coefficients[1, "Estimate"]
se <- coefficients[1, "Std. Error"]

# Add the results to the estimator table
est_table <- est_table %>%
  add_row(Model = paste("Col", col, "-" , var),
          Estimate = est,
          Std.Error = se)

# For Inter state specification   
ols_formula <- as.formula(paste(inter_state ~ wheat_aid + risocode + year:wb_region, US_controls, country_chars_controls, cereals_controls, weather_controls , sep = " + "))
inter_state_res <- plm(ols_formula, data = subset_data, index = c("risocode", "year"), model = "within", effect = "twoways")


# Extract coefficients and clustered standard errors
coefficients <- coeftest(var, vcov = vcovHC(inter_state_res, cluster = "group"))
est <- coefficients[1, "Estimate"]
se <- coefficients[1, "Std. Error"]

# Add the results to the estimator table
est_table <- est_table %>%
  add_row(Model = paste("Col", col, "-" , var),
          Estimate = est,
          Std.Error = se)
```


MIKI FROM HERE IGNORE!
MIKI FROM HERE IGNORE!

```{r}
# Perform reduced form estimates
for (col in 1:7) {
  # Subset the data for in-sample observations
  data_subset <- subset(data_reduced_form, in_sample == 1)
  
  # Add additional controls based on the column number
  if (col > 1) {
    controls <- switch(col - 1,
                       US_controls,
                       weather_controls,
                       country_chars_controls,
                       cereals_controls,
                       cereals_controls,
                       cereals_controls)
    
    # Append the additional controls to the formula
    rf_formula <- update(rf_formula, . ~ . + eval(parse(text = controls)))
  }
  
  # Fit the reduced form model using panel data regression
  model <- plm(rf_formula, data = data_subset, index = c("risocode", "year"), model = "within", effect = "twoways")
  
  # Extract coefficients and clustered standard errors
  coefficients <- coeftest(model, vcov = vcovHC(model, cluster = "group"))
  est <- coefficients[2, "Estimate"]
  se <- coefficients[2, "Cluster.S.E."]
  
  # Add the results to the estimator table
  est_table <- est_table %>%
    add_row(Model = paste("Col", col, "-", ifelse(col == 1, "No Controls", controls), "(RF)"),
            Estimate = est,
            Std.Error = se)
  
  # Reset the formula for

  rf_formula <- formula(instrument ~ as.factor(risocode) + as.factor(year) * wb_region)
}

# Print the estimator table
print(est_table)
```




MIKI FROM HERE IGNORE!
```{r}

other version -
  # Load the required packages
library(plm)
library(sandwich)

# Load the data file "in_sample.dta"
data <- read.dta("in_sample.dta")

# Define the panel data structure
pdata <- pdata.frame(data, index = c("risocode", "year"))

# Generating in-sample indicator so that all specifications have the same number of observations
pdata$in_sample <- ifelse(pdata$e_sample == 1, 1, 0)

# Define the baseline controls and other control variables
US_controls <- c("oil_fadum_avg", "US_income_fadum_avg", "US_democ_pres_fadum_avg")
weather_controls <- c("all_Precip_jan-all_Precip_dec", "all_Temp_jan-all_Temp_dec", "all_Precip_jan_faavg-all_Precip_dec_faavg", "all_Temp_jan_faavg-all_Temp_dec_faavg")
country_chars_controls <- c("gdp_y2-gdp_y36", "usmil_y2-usmil_y36", "usec_y2-usec_y36")
cereals_controls <- c("rcereal_y2-rcereal_y36", "rimport_y2-rimport_y36")
baseline_controls <- c(US_controls, weather_controls, country_chars_controls, cereals_controls)

# Create a data frame to store the results
results <- data.frame(matrix(ncol = 7, nrow = 2))
colnames(results) <- c("Model 1", "Model 2", "Model 3", "Model 4", "Model 5", "Model 6", "Model 7")
rownames(results) <- c("OLS Estimates", "Reduced Form")

# Panel A: OLS Estimates
# Col 1
model1 <- plm(wheat_aid ~ any_war + factor(year) * factor(wb_region), data = pdata[pdata$year >= 1971 & pdata$year <= 2006 & pdata$in_sample == 1,], model = "within")
results[1, 1] <- summary(model1)$coef[2, 1]  # Beta coefficient
results[2, 1] <- sqrt(diag(vcovHC(model1, cluster = "group")))  # Clustered standard error

# Col 2
model2 <- plm(wheat_aid ~ any_war + US_controls + factor(year) * factor(wb_region), data = pdata[pdata$year >= 1971 & pdata$year <= 2006 & pdata$in_sample == 1,], model = "within")
results[1, 2] <- summary(model2)$coef[2, 1]
results[2, 2] <- sqrt(diag(vcovHC(model2, cluster = "group")))

# Col 3
model3 <- plm(wheat_aid ~ any_war + weather_controls + US_controls + factor(year) * factor(wb_region), data = pdata[pdata$year >= 1971 & pdata$year <= 2006 & pdata$in_sample == 1,], model = "within")
results[1, 3] <- summary(model3)$coef[2, 1]
results[2, 3] <- sqrt(diag(vcovHC(model3, cluster = "group")))

# Col 4
model4 <- plm(wheat_aid ~ any_war + country_chars_controls + weather_controls + US_controls + factor(year) * factor(wb_region), data = pdata[pdata$year >= 1971 & pdata$year <= 2006 & pdata$in_sample == 1,], model = "within")
results[1, 4] <- summary(model4)$coef[2, 1]
results[2, 4] <- sqrt(diag(vcovHC(model4, cluster = "group")))

# Panel B: Reduced Form
# Col 5
model5 <- plm(wheat_aid ~ any_war + factor(risocode) + factor(year) * factor(wb_region), data = pdata[pdata$year >= 1971 & pdata$year <= 2006 & pdata$in_sample == 1,], model = "within")
results[1, 5] <- summary(model5)$coef[2, 1]
results[2, 5] <- sqrt(diag(vcovHC(model5, cluster = "group")))

# Panel C: Second Stage of IV
# Col 6
model6 <- ivreg(wheat_aid ~ factor(risocode) + factor(year) * factor(wb_region) | country_chars_controls + weather_controls + US_controls + factor(risocode) + factor(year) * factor(wb_region), data = pdata[pdata$year >= 1971 & pdata$year <= 2006 & pdata$in_sample == 1,])
results[1, 6] <- summary(model6)$coef[2, 1]
results[2, 6] <- sqrt(diag(vcovHC(model6, cluster = "group")))

# Panel D: First Stage of IV
# Col 7
model7 <- ivreg(any_war ~ country_chars_controls + weather_controls + US_controls + factor(risocode) + factor(year) * factor(wb_region), data = pdata[pdata$year >= 1971 & pdata$year <= 2006 & pdata$in_sample == 1,])
results[1, 7] <- summary(model7)$coef[2, 1]
results[2, 7] <- sqrt(diag(vcovHC(model7, cluster = "group")))

# Print the results table
print(results)
```

# ML Extension

## IV estimation with Lasso-based first stage

# Prediction

## Data Preperation
```{r}
set.seed(42)
split <- data %>% initial_split(prop = 0.7)
train <- training(split)
test <- testing(split)
```

## Model Specification 
```{r}
# Cross validation folds
cv_folds <- train %>%
  vfold_cv(v = 5)

# For stacking
ctrl_grid <- control_stack_grid()

# Recipe (data processing)
train_rec <- recipe(any_war ~ . , data = train) %>%
  step_dummy(all_nominal_predictors()) %>% 
  step_normalize(all_predictors()) %>%
  step_zv()
  step_zv(all_predictors())


train_prep <- train_rec %>% prep()
```

## Lasso Model 
```{r}
# Model definition
lasso_model <-
  linear_reg(penalty = tune(), mixture = 1) %>%
    set_engine("glmnet") %>%
    set_mode("regression")

# Define parameters for tuning
lasso_grid <- grid_regular(penalty(c(-3,-1.5)), levels = 30)

# Combine models and workflow
lasso_wf <- workflow() %>%
  add_recipe(train_rec) %>%
  add_model(lasso_model)

# Tune parameters
lasso_results <- lasso_wf %>%
  tune_grid(grid = lasso_grid,
            resamples = cv_folds,
            control = ctrl_grid)

lasso_results %>% show_best(metric = "rmse") %>% select(-c(n, .config)) %>% tidy()
```


```{r}
# Visualize results
plot(lasso_results)??? 
  
# fit the model 
lasso_best <- lasso_results %>% select_best(metric = "rmse")

# Finalize workflow
lasso_final <- finalize_workflow(lasso_wf, lasso_best)
lasso_fit <- lasso_final %>% fit(train)
```

## Random forests model

```{r}
#Define the  formula - 
formula_full <- any_war ~ .


#define the fit - 
fitControl <- trainControl(
  method = "repeatedcv",
  number = 5,
  repeats = 3
  )

# Full formula variation
rf_model <- train(form =  formula_full,
                  data = train,
                  metric='Accuracy',
                  method = "rf",
                  trControl = fitControl
                  )

```


```{r}
stack <- stacks() %>%
  add_candidates(lasso_results) %>%
  add_candidates(rf_model)

stack_model <- stack %>%
  blend_predictions()

autoplot(stack_model, type = "weights")
```






